[1m============================= test session starts =============================[0m
platform win32 -- Python 3.10.18, pytest-9.0.2, pluggy-1.6.0 -- D:\code-repos\cuvis-ai-core\.venv\Scripts\python.exe
cachedir: .pytest_cache
rootdir: D:\code-repos\cuvis-ai-core
configfile: pytest.ini
plugins: hydra-core-1.3.2, asyncio-1.3.0, cov-7.0.0, mock-3.15.1
asyncio: mode=auto, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
[1mcollecting ... [0mcollected 326 items / 9 errors

<Dir cuvis-ai-core>
  <Package tests>
    <Dir config>
      <Module test_json_schema.py>
        <Function test_optimizer_schema_generation>
        <Function test_training_schema_nested>
        <Function test_schema_generation_for_all_types>
      <Module test_pydantic_models.py>
        <Class TestOptimizerConfig>
          <Function test_valid_config>
          <Function test_lr_min_constraint>
          <Function test_lr_max_constraint>
          <Function test_weight_decay_constraint>
        <Class TestTrainingConfig>
          <Function test_nested_configs>
          <Function test_max_epochs_constraint>
          <Function test_optional_scheduler>
        <Class TestCallbackConfig>
          <Function test_callbacks_structure>
        <Class TestProtoSerialization>
          <Function test_optimizer_proto_roundtrip>
          <Function test_training_proto_roundtrip>
          <Function test_trainrun_proto_roundtrip>
        <Function test_trainrun_json_roundtrip>
    <Package grpc_api>
      <Module test_advanced_features.py>
        <Class TestCheckpointManagement>
          Checkpoint save/load via SavePipeline/LoadPipeline RPCs.
          <Function test_save_checkpoint_invalid_session>
            Test saving pipeline with invalid session (checkpoint equivalent).
        <Class TestTrainingCapabilities>
          Training capability discovery.
          <Function test_get_training_capabilities>
          <Function test_callback_info_structure>
        <Class TestConfigValidation>
          Training config validation RPC.
          <Function test_validate_valid_config>
          <Function test_validate_invalid_optimizer>
          <Function test_validate_invalid_learning_rate>
        <Class TestComplexInputs>
          Complex input parsing (bboxes, points, text prompts).
          <Function test_inference_with_bounding_boxes>
          <Function test_inference_with_points>
          <Function test_inference_with_text_prompt>
          <Function test_inference_with_multiple_input_types>
      <Module test_end_to_end_workflows.py>
        End-to-end workflow tests (Task 5.5).
        
        These tests verify complete workflows as described in the Phase 4 documentation.
        <Class TestWorkflow1_TrainFromScratch>
          Workflow 1: Train from Scratch (as per Phase 4 doc).
          
          Steps:
          1. CreateSession with pipeline structure (no weights)
          2. Train with explicit data and training configs
          3. SavePipeline for deployment
          4. SaveTrainRun for reproducibility
          5. CloseSession
          <Function test_complete_workflow>
            Test the complete train-from-scratch workflow.
        <Class TestWorkflow2_InferenceWithPretrained>
          Workflow 2: Inference with Pre-trained Model.
          
          Steps:
          1. CreateSession with pre-trained pipeline
          2. Run inference
          3. Verify outputs
          4. CloseSession
          <Function test_complete_workflow>
            Test inference with a pre-trained model using shared fixture.
        <Class TestWorkflow3_ResumeTraining>
          Workflow 3: Resume Training.
          
          Steps:
          1. RestoreTrainRun
          2. Continue training with modified config
          3. SavePipeline with updated weights
          4. SaveTrainRun as new version
          <Function test_complete_workflow>
            Test resuming training from a saved experiment.
        <Class TestWorkflow4_DiscoverAndInspect>
          Workflow 4: Discover and Inspect Pipelinees.
          
          Steps:
          1. ListAvailablePipelinees
          2. Filter by tag
          3. GetPipelineInfo for specific pipeline
          4. CreateSession based on discovered pipeline
          <Function test_complete_workflow>
            Test pipeline discovery and inspection workflow using shared setup.
        <Class TestWorkflow5_LoadPipelineWeights>
          Workflow 5: Load Pipeline Weights.
          
          Steps:
          1. CreateSession with structure only
          2. Later, LoadPipeline with weights
          3. Run inference
          <Function test_complete_workflow>
            Test loading weights into an existing session using shared fixture.
        <Class TestWorkflowIntegration>
          Test combinations and interactions between workflows.
          <Function test_multiple_sessions_parallel>
            Test that multiple sessions can coexist using shared trained session.
          <Function test_inference_modes_with_pretrained[wavelength_dependent]>
            Test different inference modes using the shared pretrained pipeline.
          <Function test_inference_modes_with_pretrained[random]>
            Test different inference modes using the shared pretrained pipeline.
          <Function test_session_reuse_after_save_load>
            Test that a session can be reused after save/load operations using shared fixture.
      <Module test_experiment_management.py>
        Integration tests for experiment management functionality (Task 5.4).
        
        Optimized to minimize redundant training by using module-scoped shared fixtures
        and reusing trained sessions across multiple tests where appropriate.
        <Class TestSaveTrainRun>
          Test the SaveTrainRun RPC method using shared trained session.
          <Function test_save_trainrun_creates_manifest_and_has_valid_structure>
            Test that SaveTrainRun creates valid YAML with references, not data copies.
          <Function test_save_trainrun_without_training>
            Test that saving trainrun before training either succeeds or fails gracefully.
          <Function test_save_trainrun_with_and_without_weights[True]>
            Test SaveTrainRun with save_weights=True/False parameter.
          <Function test_save_trainrun_with_and_without_weights[False]>
            Test SaveTrainRun with save_weights=True/False parameter.
        <Class TestRestoreTrainRun>
          Test the RestoreTrainRun RPC method using pre-saved artifacts.
          <Function test_restore_trainrun_creates_session>
            Test that RestoreTrainRun creates a new session.
          <Function test_restore_trainrun_loads_pipeline_and_runs_inference>
            Test that pipeline is correctly loaded and can perform inference.
          <Function test_restore_trainrun_invalid_file>
            Test error handling for non-existent trainrun file.
          <Function test_restore_trainrun_missing_pipeline_nodes>
            Test error when trainrun references invalid pipeline (empty nodes).
          <Function test_restore_trainrun_with_weights>
            Test that RestoreTrainRun can load weights and initialize statistical nodes.
          <Function test_restore_trainrun_with_missing_weights>
            Test that RestoreTrainRun handles missing weights gracefully.
        <Class TestWeightTransfer>
          Test that weights are correctly transferred during save/restore.
          <Function test_weights_functional_verification>
            Test that restored weights produce consistent outputs.
          <Function test_strict_and_nonstrict_loading[True]>
            Test strict and non-strict weight loading behavior.
          <Function test_strict_and_nonstrict_loading[False]>
            Test strict and non-strict weight loading behavior.
          <Function test_statistical_node_inference_without_refit>
            Test that statistical nodes work after weight restore without re-fitting.
        <Class TestExperimentWorkflow>
          Test complete experiment workflows.
          <Function test_train_save_restore_cycle>
            Test complete workflow: train -> save trainrun -> restore -> verify.
          <Function test_experiment_reproducibility>
            Test that restored experiment config is accessible for re-training.
          <Function test_resume_training_workflow>
            Test resume training workflow: restore with weights -> continue training.
      <Module test_file_resolution.py>
        <Function test_find_config_file_relative>
        <Function test_find_config_file_absolute>
        <Function test_find_weights_file>
        <Function test_missing_weights_file_raises>
      <Module test_gradient_training.py>
        <Class TestGradientTraining>
          Gradient training workflow tests.
          <Function test_gradient_training_comprehensive>
            Comprehensive test that validates all aspects of gradient training in a single run.
            
            This test combines multiple validation checks that were previously in separate tests
            to avoid running training multiple times. It validates:
            - Training completion and progress updates
            - Loss reporting
            - Metrics reporting
            - Stage reporting
            - Epoch progression
      <Module test_grpc_proto_contract.py>
        <Function test_config_messages_use_bytes>
          Verify all config messages use bytes config_bytes field.
        <Function test_trainrun_naming>
          Verify Experiment renamed to TrainRun.
        <Function test_new_session_rpcs_exist>
          Verify new session management RPCs defined.
        <Function test_new_config_rpcs_exist>
          Verify new config resolution RPCs defined.
        <Function test_new_pipeline_rpcs_exist>
          Verify new pipeline building RPCs defined.
        <Function test_load_pipeline_uses_wrapper>
          LoadPipelineRequest should expose typed PipelineConfig wrapper.
        <Function test_load_weights_oneof>
          Verify LoadPipelineWeightsRequest supports both weight sources.
      <Module test_helpers.py>
        Test helper functions in cuvis_ai/grpc/helpers.py.
        <Class TestPipelinePathResolution>
          Test pipeline path resolution logic.
          <Function test_resolve_pipeline_path_with_short_name>
            Test resolving pipeline by short name (e.g., 'statistical_based').
          <Function test_resolve_pipeline_path_with_extension>
            Test resolving pipeline with explicit .yaml extension.
          <Function test_resolve_pipeline_path_absolute>
            Test pipeline resolution with absolute path.
          <Function test_resolve_pipeline_path_not_found>
            Test that FileNotFoundError is raised for missing pipeline.
        <Class TestWeightsFileResolution>
          Test weights file resolution logic.
          <Function test_find_weights_file_in_search_paths>
            Test finding weights file across search paths.
          <Function test_find_weights_file_without_extension>
            Test finding weights file when extension is not provided.
          <Function test_find_weights_file_absolute_path>
            Test finding weights with absolute path.
          <Function test_find_weights_file_not_found>
            Test that FileNotFoundError is raised when weights not found.
        <Class TestConfigRegistry>
          Test config type registry and schema generation.
          <Function test_get_config_class_valid_types>
            Test getting config classes for valid types.
          <Function test_get_config_class_invalid_type>
            Test that invalid config type raises ValueError.
          <Function test_generate_json_schema_structure>
            Test JSON schema generation produces valid schema.
          <Function test_generate_json_schema_has_required_fields>
            Test that schema includes required fields.
          <Function test_validate_config_dict_valid>
            Test validation with valid config dictionary.
          <Function test_validate_config_dict_invalid>
            Test validation with invalid config dictionary.
        <Class TestConfigOverrideUtility>
          Tests for apply_config_overrides helper.
          <Function test_override_with_list_format>
          <Function test_override_with_dict_format>
          <Function test_override_nested_and_indices>
          <Function test_invalid_override_format_raises>
        <Class TestHydraConfigResolution>
          Test Hydra-based config resolution.
          <Function test_resolve_config_with_hydra_trainrun>
            Test resolving trainrun config with Hydra composition.
          <Function test_resolve_config_with_hydra_file_not_found>
            Test that FileNotFoundError is raised when config not found.
          <Function test_resolve_config_with_hydra_validation_error>
            Test that validation error is raised for invalid config.
      <Module test_hydra_composition.py>
        <Function test_basic_config_resolution>
          Test basic Hydra config resolution using existing fixtures.
        <Function test_config_resolution_with_overrides>
          Test Hydra config resolution with overrides using existing fixtures.
        <Function test_config_not_found>
          Test error when config file not found.
        <Function test_multiple_search_paths>
          Test config resolution with multiple search paths using existing fixtures.
        <Function test_trainrun_resolution_with_config_root>
          Trainrun config should compose against the config root (defaults across groups).
      <Module test_introspection.py>
        <Class TestGetPipelineInputs>
          <Function test_get_pipeline_inputs>
          <Function test_input_specs_have_details>
          <Function test_invalid_session>
        <Class TestGetPipelineOutputs>
          <Function test_get_pipeline_outputs>
          <Function test_output_specs_have_details>
        <Class TestGetPipelineVisualization>
          <Function test_get_visualization_png>
          <Function test_get_visualization_svg>
          <Function test_default_format_png>
      <Module test_performance.py>
        <Class TestPerformance>
          Lightweight performance smoke tests.
          <Function test_session_creation_performance>
            Ensure session creation stays reasonably fast without relying on pytest-benchmark.
          <Function test_inference_latency>
          <Function test_throughput>
      <Module test_pipeline_discovery.py>
        Integration tests for pipeline discovery functionality (Task 5.2).
        <Class TestListAvailablePipelinees>
          Test the ListAvailablePipelinees RPC method.
          <Function test_list_all_pipelinees>
          <Function test_list_with_tag_filter_statistical>
          <Function test_list_with_tag_filter_gradient>
          <Function test_list_with_unknown_tag>
          <Function test_list_empty_directory>
          <Function test_list_includes_weights_info>
        <Class TestGetPipelineInfo>
          Test the GetPipelineInfo RPC method.
          <Function test_get_pipeline_info_valid>
          <Function test_get_pipeline_info_with_yaml_content>
          <Function test_get_pipeline_info_invalid>
          <Function test_get_pipeline_info_metadata>
      <Module test_pipeline_management.py>
        Integration tests for pipeline management functionality (Task 5.3).
        <Class TestSavePipeline>
          Test the SavePipeline RPC method.
          <Function test_save_pipeline_creates_yaml_and_pt>
            Test that SavePipeline creates both .yaml and .pt files.
          <Function test_save_pipeline_with_metadata>
            Test that metadata is correctly saved.
          <Function test_save_pipeline_invalid_session>
            Test error handling for invalid session ID.
          <Function test_save_pipeline_creates_directories>
            Test that SavePipeline creates parent directories if needed.
        <Class TestLoadPipeline>
          Test the LoadPipeline RPC method.
          <Function test_load_pipeline_with_weights_default>
            Test LoadPipeline loads weights when weights_path is provided.
          <Function test_load_pipeline_without_weights>
            Test LoadPipeline without providing weights_path loads structure only.
          <Function test_load_pipeline_missing_pt_error>
            Test error when an explicit weights_path does not exist.
          <Function test_load_pipeline_strict_mode>
            Test strict weight loading mode.
          <Function test_load_pipeline_non_strict_mode>
            Test non-strict weight loading allows missing keys.
          <Function test_load_pipeline_updates_session>
            Test that LoadPipeline properly updates the session pipeline.
        <Class TestPipelineRoundTrip>
          Test complete save/load cycles.
          <Function test_save_load_preserves_structure>
            Test that saving and loading preserves pipeline structure.
      <Module test_production_server.py>
        <Function test_load_tls_credentials_missing_files>
          TLS setup should fail fast when files are missing.
        <Function test_setup_logging_uses_json_formatter>
          Logging helper should apply JSON formatter.
        <Function test_server_start_and_shutdown_updates_health_status>
          Server should start, report healthy, then mark not serving on shutdown.
      <Module test_proto_converters.py>
        <Class TestProtoToNumpy>
          Test proto \u2192 numpy conversion
          <Function test_proto_to_numpy_float32>
            Test converting float32 tensor proto to numpy
          <Function test_proto_to_numpy_int32>
            Test converting int32 tensor proto to numpy
          <Function test_proto_to_numpy_invalid_dtype>
            Test error handling for unsupported dtype
          <Function test_proto_to_numpy_empty_tensor>
            Test handling empty tensors
          <Function test_proto_to_numpy_writable_by_default>
            Test that proto_to_numpy returns writable arrays by default
          <Function test_proto_to_numpy_copy_true>
            Test proto_to_numpy with copy=True returns writable array
          <Function test_proto_to_numpy_copy_false>
            Test proto_to_numpy with copy=False returns read-only view
        <Class TestNumpyToProto>
          Test numpy \u2192 proto conversion
          <Function test_numpy_to_proto_float32>
            Test converting numpy array to proto
          <Function test_numpy_to_proto_roundtrip>
            Test numpy \u2192 proto \u2192 numpy preserves data
        <Class TestTorchConversion>
          Test torch tensor conversion
          <Function test_proto_to_tensor>
            Test proto \u2192 torch tensor conversion
          <Function test_tensor_to_proto>
            Test torch tensor \u2192 proto conversion
          <Function test_tensor_to_proto_roundtrip>
            Test tensor \u2192 proto \u2192 tensor preserves data
        <Class TestProcessingModeMapping>
          Test ProcessingMode enum mapping
          <Function test_processing_mode_to_cuvis>
            Test proto ProcessingMode \u2192 cuvis ProcessingMode
          <Function test_processing_mode_invalid>
            Test error handling for invalid processing mode
          <Function test_processing_mode_new_values>
            Test new ProcessingMode enum values (DarkSubtract, SpectralRadiance)
          <Function test_processing_mode_enum_values>
            Test that all ProcessingMode enum values are correctly defined
      <Module test_proto_generation.py>
        <Class TestProtoDefinitions>
          Verify proto definitions are generated correctly
          <Function test_tensor_message_exists>
            Verify Tensor message has required fields
          <Function test_data_config_message_exists>
            Verify DataConfig message structure
          <Function test_context_message_exists>
            Verify Context message structure
          <Function test_execution_stage_enum>
            Verify ExecutionStage enum values
          <Function test_dtype_enum>
            Verify DType enum values
          <Function test_processing_mode_enum>
            Verify ProcessingMode enum values
          <Function test_train_status_enum>
            Verify TrainStatus enum values
          <Function test_point_type_enum>
            Verify PointType enum values
      <Module test_service_basic.py>
        <Class TestCreateAndClose>
          <Function test_create_session_returns_id>
            Test creating a session with new four-step workflow.
          <Function test_create_session_with_weights>
            Test creating a session with pre-trained weights using four-step workflow.
          <Function test_create_session_invalid_pipeline>
            Test error handling for non-existent pipeline in four-step workflow.
          <Function test_close_session_success>
            Test closing a session successfully using session fixture.
          <Function test_close_session_not_found>
        <Class TestInference>
          <Function test_inference_returns_outputs>
          <Function test_inference_output_filtering>
          <Function test_inference_invalid_session>
          <Function test_inference_missing_cube>
            Test inference with missing cube using session fixture.
      <Module test_session_isolation.py>
        <Function test_multiple_sessions_independent>
          Test that multiple sessions maintain independent state.
        <Function test_session_lifecycle>
          Test session creation and cleanup.
        <Function test_invalid_session_access>
          Test error on accessing non-existent session.
      <Module test_session_manager.py>
        <Class TestSessionManager>
          <Function test_create_session_returns_unique_id>
          <Function test_get_session_returns_state>
          <Function test_pipeline_config_property_derives_from_pipeline>
          <Function test_get_session_nonexistent_raises_error>
          <Function test_close_session_removes_state>
          <Function test_close_nonexistent_session_raises_error>
          <Function test_get_session_updates_last_accessed>
          <Function test_cleanup_old_sessions>
          <Function test_create_session_without_data_config>
            Test creating an inference-only session (no trainrun_config).
          <Function test_session_state_with_optional_data_config>
            Test that session state properly handles optional trainrun_config.
      <Module test_statistical_training.py>
        <Class TestStatisticalTraining>
          Test statistical training workflow
          <Function test_train_statistical_completes>
            Test that statistical training completes successfully
          <Function test_statistical_training_updates_pipeline>
            Test that statistical training updates pipeline nodes
          <Function test_statistical_training_status>
            Test progress status during statistical training
          <Function test_invalid_session_training>
            Test error for training with invalid session
          <Function test_get_train_status>
            Test GetTrainStatus RPC
          <Function test_train_without_data_config_fails>
            Test that training fails gracefully when data_config is not provided
    <Dir integration>
      <Module test_4step_workflow.py>
        <Function test_complete_four_step_flow>
          End-to-end happy path for the new explicit workflow.
      <Module test_config_resolution.py>
        <Function test_config_resolution_and_validation>
          Resolve, introspect, and validate configs via new RPCs.
      <Module test_dependencies_compatibility.py>
        <Function test_existing_code_still_imports>
          Verify existing code can still import (with deprecations).
        <Function test_pydantic_hydra_integration>
          Test Pydantic and Hydra work together.
      <Module test_error_cases.py>
        Integration tests for error handling and edge cases.
        <Class TestErrorCases>
          Test error handling across gRPC API.
          <Function test_invalid_session_id>
            Test operations with invalid session ID.
          <Function test_train_without_trainrun_config>
            Test training without setting TrainRunConfig.
          <Function test_resolve_config_file_not_found>
            Test ResolveConfig with non-existent file.
          <Function test_resolve_config_invalid_yaml>
            Test ResolveConfig with malformed YAML.
          <Function test_resolve_config_validation_error>
            Test ResolveConfig with config that fails Pydantic validation.
          <Function test_invalid_config_type>
            Test ResolveConfig with invalid config type.
          <Function test_close_nonexistent_session>
            Test closing a non-existent session.
          <Function test_double_close_session>
            Test closing a session twice.
          <Function test_inference_without_pipeline>
            Test inference on session without pipeline.
          <Function test_invalid_override_syntax>
            Test ResolveConfig with invalid override syntax.
          <Function test_concurrent_operations_same_session>
            Test that concurrent operations on same session handle gracefully.
          <Function test_missing_required_inputs>
            Test inference with missing required inputs.
      <Module test_pipeline_precedence.py>
        <Function test_pipeline_conflict_rejected>
          TrainRun pipeline must match already-built pipeline.
        <Function test_pipeline_built_from_trainrun_when_missing>
          TrainRunConfig should build pipeline when session has none.
      <Module test_pydantic_integration.py>
        <Function test_complete_trainrun_serialization>
          Test complete train run config serialization.
        <Function test_yaml_to_pydantic>
          Test loading YAML-like mapping into Pydantic model.
      <Module test_search_paths.py>
        Integration tests for custom search path configuration.
        <Class TestSearchPaths>
          Test custom search path configuration through gRPC API.
          <Function test_set_session_search_paths>
            Test setting custom search paths for a session.
          <Function test_append_search_paths>
            Test appending to existing search paths.
          <Function test_resolve_config_from_custom_path>
            Test resolving config from custom search path.
          <Function test_search_path_precedence>
            Test that earlier search paths have precedence.
          <Function test_search_paths_not_found>
            Test error when config not found in any search path.
          <Function test_search_paths_persist_across_operations>
            Test that search paths persist across multiple operations in a session.
      <Module test_weight_loading.py>
        Integration tests for pipeline weight loading scenarios.
        <Class TestWeightLoading>
          Test weight loading through gRPC API.
          <Function test_load_weights_from_file_path>
            Test loading weights from file path via LoadPipelineWeights RPC.
          <Function test_load_weights_from_bytes>
            Test client-side weight loading by sending bytes.
          <Function test_load_weights_strict_mode_mismatch>
            Test that strict mode detects weight mismatches.
          <Function test_load_weights_file_not_found>
            Test error handling when weights file doesn't exist.
          <Function test_load_weights_without_pipeline>
            Test that loading weights without pipeline fails gracefully.
          <Function test_load_weights_co_located_with_pipeline>
            Test loading co-located weights (pipeline.yaml + pipeline.pt).
    <Dir node>
      <Module test_node_serialization.py>
        Tests for individual node serialization patterns.
        <Function test_all_nodes_use_state_dict_only>
          Verify that all nodes can be serialized using only state_dict.
        <Function test_no_custom_serialize_methods_needed>
          Verify that nodes don't need custom serialize/load methods.
        <Function test_node_inherits_pytorch_serialization>
          Test that all nodes inherit state_dict/load_state_dict from nn.Module.
        <Function test_validate_serialization_support_method>
          Test node validation method works correctly.
        <Function test_buffer_registration_for_statistical_nodes>
          Test that statistical nodes properly register buffers.
        <Function test_trainable_node_parameter_conversion>
          Test that trainable nodes convert buffers to parameters correctly.
        <Function test_non_persistent_buffers_not_serialized>
          Test that non-persistent buffers are excluded from state_dict.
        <Function test_state_dict_handles_nan_buffers>
          Test that state_dict correctly handles NaN-initialized buffers.
        <Function test_hparams_separate_from_state>
          Test that hyperparameters are separate from state_dict.
      <Module test_plugin_system.py>
        Tests for the NodeRegistry plugin system (cuvis-ai-core).
        <Function test_plugin_config_validation>
        <Function test_plugin_manifest_validation>
        <Function test_local_plugin_loading>
        <Function test_manifest_relative_path_resolution>
        <Function test_pipeline_integration_with_plugin>
    <Package node_registry>
      <Module test_node_registry.py>
        Tests for NodeRegistry.
        <Class TestNodeRegistry>
          Test NodeRegistry functionality.
          <Function test_register_decorator>
            Test @register decorator.
          <Function test_register_duplicate_raises_error>
            Test registering duplicate node raises error.
          <Function test_get_builtin_node>
            Test getting built-in node by name.
          <Function test_get_custom_node_via_importlib>
            Test getting custom node via full import path.
          <Function test_get_missing_node_raises_error>
            Test getting non-existent node raises clear error.
          <Function test_get_invalid_import_path_raises_error>
            Test invalid import path raises ImportError.
          <Function test_get_missing_class_in_module_raises_error>
            Test getting non-existent class from valid module raises AttributeError.
          <Function test_list_builtin_nodes>
            Test listing all registered nodes.
          <Function test_auto_register_package>
            Test auto-registering entire package.
          <Function test_clear_registry>
            Test clearing registry.
          <Function test_get_after_auto_register>
            Test getting nodes after auto-registration.
          <Function test_import_from_path_invalid_format>
            Test _import_from_path with invalid format raises ValueError.
          <Function test_import_from_path_not_a_class>
            Test importing something that's not a class raises TypeError.
          <Function test_auto_register_invalid_package>
            Test auto-registering invalid package raises ImportError.
          <Function test_auto_register_not_a_package>
            Test auto-registering a module (not package) raises ValueError.
          <Function test_registry_error_message_includes_available_nodes>
            Test that error message includes list of available nodes.
        <Class TestNodeRegistryIntegration>
          Integration tests with actual cuvis_ai nodes.
          <Function test_can_instantiate_registered_nodes>
            Test that registered nodes can be instantiated.
          <Function test_multiple_node_types_registered>
            Test that various node types are registered.
          <Function test_registry_preserves_node_class_identity>
            Test that registry returns the same class object.
    <Dir pipeline>
      <Module test_graph_connections.py>
        Test suite for Graph connection API with port-based wiring.
        <Class TestGraphConnectionBasics>
          Test basic connection operations.
          <Function test_connect_two_nodes_single_syntax>
            Connecting two nodes with single connection syntax should succeed.
          <Function test_connect_multiple_connections_batch_syntax>
            Batch connection syntax should create multiple edges.
        <Class TestConnectionValidation>
          Test connection validation logic.
          <Function test_connecting_incompatible_dtypes_raises_error>
            Connecting different dtypes should raise PortCompatibilityError.
          <Function test_connecting_incompatible_shapes_raises_error>
            Connecting mismatched shapes should raise PortCompatibilityError.
          <Function test_connecting_compatible_flexible_shapes_succeeds>
            Flexible shapes with -1 should be compatible.
        <Class TestMultiDiGraphIntegration>
          Test MultiDiGraph structure and edge attributes.
          <Function test_graph_uses_multidigraph>
            Graph.graph should be a NetworkX MultiDiGraph.
          <Function test_multiple_connections_between_same_nodes>
            Multiple connections between same node pair should be supported.
          <Function test_edge_iteration_includes_all_connections>
            Edge iteration should include all multi-edges with data.
      <Module test_graph_routing.py>
        Test suite for CuvisPipeline.forward() port-based routing.
        
        Converted from test_executor_routing.py to use pipeline.forward() instead of
        deprecated MemoryExecutor. Tests ensure proper data routing through typed
        ports, gradient preservation, and multiple entry inputs.
        <Class TestGraphBasicRouting>
          Test basic data routing through ports using pipeline.forward().
          <Function test_simple_linear_pipeline>
            Data should propagate through a simple A -> B pipeline.
          <Function test_graph_returns_all_outputs>
            Graph should expose every produced port value.
        <Class TestGraphGradientFlow>
          Ensure gradients are preserved through the graph.
          <Function test_gradients_flow_through_pipeline>
            Gradients should backpropagate across multiple nodes.
        <Class TestGraphMultipleConnections>
          Test routing with branching connection patterns.
          <Function test_fan_out_and_fan_in>
            Graph should handle branching graphs.
        <Class TestGraphEntryInputs>
          Test entry input specification handling.
          <Function test_multiple_entry_nodes>
            Graph should support multiple entry points from batch.
        <Class TestGraphPartialExecution>
          Test partial graph execution with upto_node.
          <Function test_upto_node_stops_execution>
            Execution should stop before upto_node.
        <Class TestGraphStageFiltering>
          Test stage-aware node execution filtering.
          <Function test_inference_stage_filters_correctly>
            Nodes should execute or skip based on stage.
      <Module test_node_ports.py>
        Test suite for Node port system integration.
        <Class TestNodePortCreation>
          Test that nodes create ports from specifications.
          <Function test_node_creates_input_ports_from_specs>
            Node should instantiate InputPort proxies for INPUT_SPECS entries.
          <Function test_node_creates_output_ports_from_specs>
            Node should instantiate OutputPort proxies for OUTPUT_SPECS entries.
          <Function test_empty_specs_create_no_ports>
            Nodes without specs should not create proxy objects.
        <Class TestNodePortAttributes>
          Test port proxy attribute access on node instances.
          <Function test_input_ports_accessible_as_attributes>
            Input ports should be exposed as attributes using their names.
          <Function test_output_ports_accessible_as_attributes>
            Output ports should be exposed as attributes using their names.
          <Function test_port_attributes_do_not_shadow_custom_attributes>
            Port creation should not remove attributes added by subclasses.
        <Class TestNodeForwardSignature>
          Test new forward() expectations using keyword arguments and dict returns.
          <Function test_forward_accepts_kwargs>
            Nodes should accept keyword arguments matching INPUT_SPECS.
          <Function test_forward_returns_dict>
            Nodes should return dictionaries keyed by OUTPUT_SPECS.
          <Function test_forward_keys_match_output_specs>
            Returned keys should align with OUTPUT_SPECS.
        <Class TestMultiplePortNodes>
          Test nodes with multiple inputs and outputs.
          <Function test_node_with_multiple_inputs>
            Node should expose all declared input ports.
          <Function test_node_with_multiple_outputs>
            Node should expose all declared output ports.
      <Module test_node_state_serialization.py>
        Comprehensive tests for node state serialization using only state_dict.
        <Class TestNodeStateSerialization>
          Test suite for node state serialization using only state_dict.
          <Function test_buffer_and_parameter_serialization>
            Test that both buffers and parameters are correctly serialized.
          <Function test_buffer_to_parameter_conversion_preserved>
            Test that buffer->parameter conversion is preserved through serialization.
          <Function test_partial_state_loading>
            Test loading with missing or extra keys.
          <Function test_pipeline_integration_with_mock_node>
            Test that mock node works correctly in pipeline serialization.
          <Function test_device_and_dtype_handling>
            Test that serialization handles device and dtype correctly.
      <Module test_ports.py>
        Test suite for port system (PortSpec, InputPort, OutputPort, DimensionResolver).
        All tests should FAIL initially until implementation is complete.
        <Class TestPortSpec>
          Test PortSpec dataclass and its methods.
          <Function test_portspec_creation_with_torch_dtype>
            Test creating PortSpec with torch dtype.
          <Function test_portspec_creation_with_python_types>
            Test creating PortSpec with Python types.
          <Function test_portspec_optional_flag>
            Test optional port specification.
          <Function test_portspec_symbolic_dimensions>
            Test symbolic dimension in shape.
        <Class TestDimensionResolver>
          Test dimension resolution logic.
          <Function test_resolve_all_flexible_dims>
            Test resolving shape with only flexible dimensions.
          <Function test_resolve_fixed_dims>
            Test resolving shape with fixed dimensions.
          <Function test_resolve_symbolic_dims_from_node_params>
            Test resolving symbolic dimensions using node parameters.
          <Function test_resolve_multiple_symbolic_dims>
            Test resolving multiple symbolic dimensions.
          <Function test_resolve_missing_node_param_raises_error>
            Test that missing node parameter raises clear error.
        <Class TestPortCompatibility>
          Test port compatibility checking.
          <Function test_identical_specs_are_compatible>
            Test that identical specs are compatible.
          <Function test_dtype_mismatch_incompatible>
            Test that dtype mismatch makes ports incompatible.
          <Function test_flexible_dims_are_compatible>
            Test that flexible dimensions are compatible with any size.
          <Function test_fixed_dim_mismatch_incompatible>
            Test that fixed dimension mismatch is incompatible.
          <Function test_shape_length_mismatch_incompatible>
            Test that different shape lengths are incompatible.
          <Function test_symbolic_dims_resolved_before_checking>
            Test that symbolic dimensions are resolved before compatibility check.
        <Class TestPortProxies>
          Test InputPort and OutputPort proxy objects.
          <Function test_output_port_creation>
            Test creating an OutputPort proxy.
          <Function test_input_port_creation>
            Test creating an InputPort proxy.
          <Function test_port_repr>
            Test port string representation.
      <Module test_runtime_io_validation.py>
        Test suite for runtime I/O validation in CuvisPipeline.
        
        Tests that nodes' actual inputs and outputs are validated against their
        INPUT_SPECS and OUTPUT_SPECS at runtime.
        <Class TestRuntimeOutputValidation>
          Test runtime output validation against OUTPUT_SPECS.
          <Function test_valid_output_passes>
            Test that correct output types pass validation.
          <Function test_wrong_dtype_output_fails>
            Test that wrong output dtype is caught.
          <Function test_wrong_shape_output_fails>
            Test that wrong output shape is caught.
          <Function test_missing_output_fails>
            Test that missing required output is caught.
          <Function test_validation_can_be_disabled>
            Test that validation can be disabled.
        <Class TestRuntimeInputValidation>
          Test runtime input validation against INPUT_SPECS.
          <Function test_wrong_dtype_input_fails>
            Test that wrong input dtype from source node is caught.
          <Function test_wrong_shape_input_fails>
            Test that wrong input shape from source node is caught.
          <Function test_flexible_dimensions_work>
            Test that flexible dimensions (-1) accept any size.
        <Class TestBinaryDeciderBug>
          Integration test that catches the BinaryDecider dtype bug.
          <Function test_binary_decider_returns_bool>
            Test that BinaryDecider now returns bool as specified.
          <Function test_binary_decider_in_pipeline_with_validation>
            Test that BinaryDecider works in pipeline with validation enabled.
      <Module test_visualizer.py>
        <Function test_graphviz_supports_phase3_styling>
        <Function test_mermaid_supports_phase3_features>
        <Function test_pipeline_visualize_method_proxy>
        <Function test_pipeline_visualize_can_render_to_file>
      <Module test_yaml_loading.py>
        Tests for YAML-based pipeline building.
        <Class TestPipelineBuilder>
          Test PipelineBuilder functionality.
          <Function test_build_simple_pipeline>
            Test building pipeline with single node.
          <Function test_build_with_connections>
            Test building pipeline with connections.
          <Function test_load_from_yaml_file>
            Test loading configuration from YAML file.
          <Function test_omegaconf_interpolation>
            Test building pipeline with hardcoded node parameters.
          <Function test_missing_node_raises_error>
            Test that missing node class raises error.
          <Function test_invalid_connection_format_raises_error>
            Test that invalid connection format raises error.
          <Function test_missing_source_node_raises_error>
            Test that missing source node raises error.
          <Function test_missing_target_node_raises_error>
            Test that missing target node raises error.
          <Function test_counter_based_naming>
            Test that counter-based naming works correctly.
          <Function test_file_not_found_raises_error>
            Test that non-existent file raises FileNotFoundError.
          <Function test_pipeline_name_from_metadata>
            Test that pipeline name is extracted from metadata.
          <Function test_pipeline_default_name>
            Test that default pipeline name is used when metadata missing.
          <Function test_empty_params>
            Test that nodes can be created without params.
          <Function test_counter_gap_preservation_on_node_removal>
            Test that counter gaps are preserved when nodes are removed and new ones added.
            
            This verifies the fix for counter assignment that uses the highest counter + 1
            instead of counting existing nodes, which prevents name collisions.
            
            Example:
                Initial: normalizer (0), normalizer-1 (1), normalizer-2 (2)
                Remove: normalizer-1 (gap at counter 1)
                Add new: normalizer-3 (3) - gap preserved, no collision
    <Dir proto>
      <Module test_proto_consistency.py>
        <Function test_no_legacy_validate_training_config_rpc>
          Ensure old ValidateTrainingConfig RPC is not reintroduced.
    <Module test_fixtures_smoke.py>
      Smoke tests to verify test infrastructure is working correctly.
      <Function test_simple_input_node_fixture>
        Verify simple_input_node fixture works.
      <Function test_simple_transform_node_fixture>
        Verify simple_transform_node fixture works.
      <Function test_mock_pt_file_fixture>
        Verify mock_pt_file fixture creates valid .pt file.
      <Function test_hyperspectral_batch_fixture>
        Verify hyperspectral_batch fixture generates correct data.
      <Function test_batch_factory_fixture>
        Verify batch_factory fixture creates customizable batches.
      <Function test_tmp_config_dir_fixture>
        Verify tmp_config_dir fixture creates directory.
      <Function test_minimal_pipeline_dict_fixture>
        Verify minimal_pipeline_dict fixture structure.

=================================== ERRORS ====================================
[31m[1m_________ ERROR collecting tests/grpc_api/test_config_preservation.py _________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\grpc_api\test_config_preservation.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
..\cuvis-ai\tests\grpc_api\test_config_preservation.py:14: in <module>
    from tests.fixtures.sessions import materialize_trainrun_config
E   ModuleNotFoundError: No module named 'tests.fixtures.sessions'[0m
[31m[1m__________ ERROR collecting tests/grpc_api/test_pipeline_builder.py ___________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\grpc_api\test_pipeline_builder.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
..\cuvis-ai\tests\grpc_api\test_pipeline_builder.py:8: in <module>
    from cuvis_ai.node.data import LentilsAnomalyDataNode
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m_______ ERROR collecting tests/integration/test_typed_io_integration.py _______[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\integration\test_typed_io_integration.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests\integration\test_typed_io_integration.py:9: in <module>
    from cuvis_ai.anomaly.rx_detector import RXGlobal
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m____________ ERROR collecting tests/node/test_node_autocomplete.py ____________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\node\test_node_autocomplete.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests\node\test_node_autocomplete.py:7: in <module>
    from cuvis_ai.node.pca import TrainablePCA
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m____________ ERROR collecting tests/pipeline/test_graph_wiring.py _____________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\pipeline\test_graph_wiring.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
..\cuvis-ai\tests\pipeline\test_graph_wiring.py:20: in <module>
    from cuvis_ai.anomaly.rx_detector import RXPerBatch
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m_______ ERROR collecting tests/pipeline/test_pipeline_introspection.py ________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\pipeline\test_pipeline_introspection.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
..\cuvis-ai\tests\pipeline\test_pipeline_introspection.py:1: in <module>
    from cuvis_ai.node.data import LentilsAnomalyDataNode
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m__________ ERROR collecting tests/pipeline/test_unique_node_names.py __________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\pipeline\test_unique_node_names.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
..\cuvis-ai\tests\pipeline\test_unique_node_names.py:5: in <module>
    from cuvis_ai.node.normalization import MinMaxNormalizer
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m_______________ ERROR collecting tests/training/test_config.py ________________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\training\test_config.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests\training\test_config.py:7: in <module>
    from cuvis_ai.anomaly.rx_logit_head import RXLogitHead
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[31m[1m__________ ERROR collecting tests/training/test_external_trainers.py __________[0m
[31mImportError while importing test module 'D:\code-repos\cuvis-ai-core\tests\training\test_external_trainers.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
C:\Users\nima.ghorbani\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\importlib\__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests\training\test_external_trainers.py:8: in <module>
    from cuvis_ai.anomaly.rx_detector import RXGlobal
E   ModuleNotFoundError: No module named 'cuvis_ai'[0m
[36m[1m=========================== short test summary info ===========================[0m
[31mERROR[0m tests/grpc_api/test_config_preservation.py
[31mERROR[0m tests/grpc_api/test_pipeline_builder.py
[31mERROR[0m tests/integration/test_typed_io_integration.py
[31mERROR[0m tests/node/test_node_autocomplete.py
[31mERROR[0m tests/pipeline/test_graph_wiring.py
[31mERROR[0m tests/pipeline/test_pipeline_introspection.py
[31mERROR[0m tests/pipeline/test_unique_node_names.py
[31mERROR[0m tests/training/test_config.py
[31mERROR[0m tests/training/test_external_trainers.py
!!!!!!!!!!!!!!!!!!! Interrupted: 9 errors during collection !!!!!!!!!!!!!!!!!!!
[31m=================== [32m326 tests collected[0m, [31m9 errors[0m[31m in 0.86s[0m[31m ====================[0m
